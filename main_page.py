# Contents of ~/my_app/streamlit_app.py
import streamlit as st

from typing import Dict, List

from transformers import (
    EncoderDecoderModel,
    GPT2Tokenizer,
    BertTokenizer,
    PreTrainedTokenizerFast,
)

from lib.tokenization_kobert import KoBertTokenizer


class KoGPT2Tokenizer(PreTrainedTokenizerFast):
    def build_inputs_with_special_tokens(self, token_ids: List[int], _) -> List[int]:
        return token_ids + [self.eos_token_id]


if "tokenizer" not in st.session_state:
    src_tokenizer = KoBertTokenizer.from_pretrained("monologg/kobert")
    trg_tokenizer = GPT2Tokenizer.from_pretrained("distilgpt2")
    # src_tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
    # trg_tokenizer = KoGPT2Tokenizer.from_pretrained(
    #     "skt/kogpt2-base-v2",
    #     bos_token="</s>",
    #     eos_token="</s>",
    #     unk_token="<unk>",
    #     pad_token="<pad>",
    #     mask_token="<mask>",
    # )
    st.session_state.tokenizer = src_tokenizer, trg_tokenizer
else:
    src_tokenizer, trg_tokenizer = st.session_state.tokenizer


@st.cache
def get_model(bos_token_id):
    model = EncoderDecoderModel.from_pretrained("dump/baseline_best_model")
    # model = EncoderDecoderModel.from_pretrained("dump/first_model")
    model.config.decoder_start_token_id = bos_token_id
    model.eval()
    # model.cuda()

    return model


model = get_model(trg_tokenizer.bos_token_id)

st.markdown("# Main page ğŸˆ")
st.sidebar.markdown("# Main page ğŸˆ\nTEAM_5ì˜ ì˜í•œë²ˆì—­ê¸° googoormì…ë‹ˆë‹¤")

st.title("googoorm")
st.subheader("ì˜-í•œ ë²ˆì—­ê¸°ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!\nìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ ë²ˆì—­ì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤")

kor = st.text_area("ì…ë ¥", placeholder="ë²ˆì—­í•  ì˜ì–´")

if st.button("ë²ˆì—­!", help="í•´ë‹¹ ì˜ì–´ ì…ë ¥ì„ ë²ˆì—­í•©ë‹ˆë‹¤."):
    embeddings = src_tokenizer(
        kor,
        return_attention_mask=False,
        return_token_type_ids=False,
        return_tensors="pt",
    )
    embeddings = {k: v for k, v in embeddings.items()}
    # embeddings = {k: v.cuda() for k, v in embeddings.items()}
    output = model.generate(**embeddings)[0, 1:-1].cpu()
    st.text_area("ì¶œë ¥", value=trg_tokenizer.decode(output), disabled=True)
    # st.text_area("ì¶œë ¥", value="ì•ˆë…•í•˜ì„¸ìš”", disabled=True)
